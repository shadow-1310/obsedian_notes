### Chinchila Scaling Law
- the relation between amount of parameters and training tokens
- training token should be ~20 times parameters