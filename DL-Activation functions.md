## Softmax
- Why do we need?
	- because output layer in neural network can have numbers ranging from -inf to +inf, which does not follow probability law.
	- to follow probability we need 2 things, 
		- sum up to 1
		- even if we add a number prob remains same.
- Solution
	- 